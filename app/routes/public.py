from __future__ import annotations

from datetime import datetime, timezone
import html
import hashlib
import json
import os
import re
import traceback
from pathlib import Path
from urllib.parse import quote_plus

from fastapi import APIRouter, Depends, Form, Request, Query
from fastapi import HTTPException
from fastapi.responses import HTMLResponse, RedirectResponse, StreamingResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from sqlalchemy.orm import Session, joinedload

from app.db import get_db
from app.models import Answer, Question, Test, TestItem
from app.seeding import seed_questions_if_empty
from app.services.reporting import build_report_context
from app.services.selection import select_balanced
from app.services.scoring import is_near_boundary, score_all
from app.services.tokens import expiry_from_choice, hash_token, new_url_token

try:
    import markdown  # type: ignore
except Exception:  # pragma: no cover
    markdown = None

try:
    from openai import AsyncOpenAI
except Exception:  # pragma: no cover
    AsyncOpenAI = None

router = APIRouter()
templates = Jinja2Templates(directory=str(Path(__file__).resolve().parents[1] / "templates"))

CSRF_COOKIE = "csrf_token"
TEST_COOKIE = "test_token"


def _app_secret() -> str:
    return os.getenv("MBTI_APP_SECRET", "dev-secret-change-me")


def _csrf_token(request: Request) -> tuple[str, bool]:
    csrf = request.cookies.get(CSRF_COOKIE)
    if csrf:
        return csrf, False
    return new_url_token(16), True


def _require_csrf(request: Request, csrf_token: str) -> None:
    cookie = request.cookies.get(CSRF_COOKIE)
    if not cookie or cookie != csrf_token:
        raise HTTPException(status_code=403, detail="CSRF æ ¡éªŒå¤±è´¥")


def _as_utc(dt: datetime) -> datetime:
    if dt.tzinfo is None:
        return dt.replace(tzinfo=timezone.utc)
    return dt.astimezone(timezone.utc)


def _get_test_from_cookie(request: Request, db: Session) -> Test:
    secret = _app_secret()

    token = request.cookies.get(TEST_COOKIE)
    if token:
        token_hash = hash_token(token, secret=secret)
        test_row = db.query(Test).filter(Test.test_token_hash == token_hash).one_or_none()
        if test_row:
            return _validate_in_progress_test(db, test_row)

    raise HTTPException(status_code=401, detail="ç¼ºå°‘æµ‹è¯•ä¼šè¯")


def _validate_in_progress_test(db: Session, test_row: Test) -> Test:
    if test_row.status != "in_progress":
        raise HTTPException(status_code=400, detail="è¯¥æµ‹è¯•å·²ç»“æŸ")
    if test_row.resume_expires_at and datetime.now(timezone.utc) > _as_utc(test_row.resume_expires_at):
        test_row.status = "expired"
        db.commit()
        raise HTTPException(status_code=401, detail="è¯¥æµ‹è¯•å·²è¿‡æœŸ")
    return test_row


@router.get("/", response_class=HTMLResponse)
def home(
    request: Request,
    db: Session = Depends(get_db),
    error: str | None = Query(None),
):
    # Minimal home page; enhanced later with resume/continue logic.
    has_in_progress = False
    try:
        _get_test_from_cookie(request, db)
        has_in_progress = True
    except HTTPException:
        has_in_progress = False

    error_message = None
    if error == "question_bank_insufficient":
        error_message = "é¢˜åº“é¢˜ç›®ä¸è¶³ï¼Œæ— æ³•æŠ½å–æ‰€éœ€é¢˜é‡ï¼›è¯·åˆ°ç®¡ç†åå°è¡¥é¢˜åå†è¯•ã€‚"
    if error == "bad_request":
        error_message = "è¯·æ±‚å‚æ•°ä¸åˆæ³•ï¼Œè¯·é‡æ–°é€‰æ‹©åå†æäº¤ã€‚"

    csrf, should_set = _csrf_token(request)
    response = templates.TemplateResponse(
        request,
        "home.html",
        {
            "now": datetime.now(timezone.utc),
            "has_in_progress": has_in_progress,
            "csrf_token": csrf,
            "error_message": error_message,
        },
    )
    if should_set:
        response.set_cookie(CSRF_COOKIE, csrf, httponly=True, samesite="lax")
    return response


@router.post("/start")
def start(
    request: Request,
    db: Session = Depends(get_db),
    mode: int = Form(...),
    resume_expiry: str = Form(...),
    csrf_token: str = Form(...),
):
    _require_csrf(request, csrf_token)

    if mode not in (20, 40, 60):
        return RedirectResponse(url="/?error=bad_request", status_code=303)

    try:
        delta = expiry_from_choice(resume_expiry)
    except ValueError:
        return RedirectResponse(url="/?error=bad_request", status_code=303)
    now = datetime.now(timezone.utc)
    resume_expires_at = None if delta is None else (now + delta)

    secret = _app_secret()

    test_token = new_url_token()
    legacy_resume_token = new_url_token()
    legacy_resume_code = new_url_token(8)

    seed_questions_if_empty(db)
    active_questions = db.query(Question).filter(Question.is_active.is_(True)).all()
    try:
        picked = select_balanced(active_questions, total=mode)
    except ValueError:
        return RedirectResponse(url="/?error=question_bank_insufficient", status_code=303)

    test_row = Test(
        mode=mode,
        target_count=mode,
        extra_max=10,
        status="in_progress",
        resume_expires_at=resume_expires_at,
        test_token_hash=hash_token(test_token, secret=secret),
        resume_token_hash=hash_token(legacy_resume_token, secret=secret),
        resume_code_hash=hash_token(legacy_resume_code, secret=secret),
    )
    db.add(test_row)
    db.flush()

    for idx, q in enumerate(picked, start=1):
        db.add(TestItem(test_id=test_row.id, position=idx, question_id=q.id, is_extra=False))

    db.commit()

    response = RedirectResponse(url="/test", status_code=303)
    max_age = None if delta is None else int(delta.total_seconds())
    response.set_cookie(TEST_COOKIE, test_token, httponly=True, samesite="lax", max_age=max_age)
    return response


@router.get("/test", response_class=HTMLResponse)
def test_page(request: Request, db: Session = Depends(get_db), pos: int | None = None):
    test_row = _get_test_from_cookie(request, db)

    rows = (
        db.query(TestItem, Question)
        .join(Question, Question.id == TestItem.question_id)
        .filter(TestItem.test_id == test_row.id)
        .order_by(TestItem.position.asc())
        .all()
    )
    if not rows:
        raise HTTPException(status_code=400, detail="è¯¥æµ‹è¯•æ²¡æœ‰é¢˜ç›®")

    items = [it for it, _q in rows]
    used_ids = {int(it.question_id) for it in items}
    answers = db.query(Answer).filter(Answer.test_id == test_row.id).all()
    answer_map = {int(a.question_id): int(a.value) for a in answers}

    questions_data = []
    for it, q in rows:
        questions_data.append(
            {
                "id": int(q.id),
                "text": q.text,
                "dimension": q.dimension,
                "agree_pole": q.agree_pole,
                "position": int(it.position),
                "is_extra": bool(it.is_extra),
            }
        )

    # Tie-breaker questions pool (preferred: source == "tie_breaker"; fallback: any unused active questions).
    # Note: the current Question model doesn't have a `category` column; `source` acts as the tie-breaker marker.
    tie_rows = db.query(Question).filter(Question.is_active.is_(True), Question.source == "tie_breaker").all()
    if not tie_rows:
        q = db.query(Question).filter(Question.is_active.is_(True))
        if used_ids:
            q = q.filter(~Question.id.in_(used_ids))
        tie_rows = q.all()

    dim_pair = {"EI": "E-I", "SN": "S-N", "TF": "T-F", "JP": "J-P"}
    tie_breakers: dict[str, list[dict[str, object]]] = {}
    for q in tie_rows:
        key = dim_pair.get(str(q.dimension), str(q.dimension))
        tie_breakers.setdefault(key, []).append(
            {
                "id": int(q.id),
                "text": q.text,
                "dimension": q.dimension,
                "agree_pole": q.agree_pole,
            }
        )

    initial_index = 0
    for idx, it in enumerate(items):
        if int(it.question_id) not in answer_map:
            initial_index = idx
            break
    else:
        initial_index = max(0, len(items) - 1)

    csrf, should_set = _csrf_token(request)

    response = templates.TemplateResponse(
        request,
        "test.html",
        {
            "questions_json": json.dumps(questions_data, ensure_ascii=False),
            "answers_json": json.dumps(answer_map, ensure_ascii=False),
            "tie_breakers_json": json.dumps(tie_breakers, ensure_ascii=False),
            "initial_index": initial_index,
            "csrf_token": csrf,
        },
    )
    if should_set:
        response.set_cookie(CSRF_COOKIE, csrf, httponly=True, samesite="lax")
    return response


@router.post("/test/answers")
async def test_answers(request: Request, db: Session = Depends(get_db)):
    payload = await request.json()
    csrf_token = payload.get("csrf_token")
    if not isinstance(csrf_token, str):
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ csrf_token")
    _require_csrf(request, csrf_token)

    test_row = _get_test_from_cookie(request, db)

    intent = payload.get("intent") or "save"
    raw_answers = payload.get("answers")
    if raw_answers is None:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ answers")

    items = (
        db.query(TestItem)
        .filter(TestItem.test_id == test_row.id)
        .order_by(TestItem.position.asc())
        .all()
    )
    item_ids = {int(it.question_id) for it in items}
    if not item_ids:
        raise HTTPException(status_code=400, detail="è¯¥æµ‹è¯•æ²¡æœ‰é¢˜ç›®")

    # De-duplicate answers by question_id; keep the last value.
    to_upsert_map: dict[int, int] = {}
    if isinstance(raw_answers, dict):
        for k, v in raw_answers.items():
            try:
                qid = int(k)
                val = int(v)
            except Exception:
                continue
            to_upsert_map[qid] = val
    elif isinstance(raw_answers, list):
        for it in raw_answers:
            if not isinstance(it, dict):
                continue
            try:
                qid = int(it.get("question_id"))
                val = int(it.get("value"))
            except Exception:
                continue
            to_upsert_map[qid] = val
    else:
        raise HTTPException(status_code=400, detail="answers æ ¼å¼ä¸åˆæ³•")

    to_upsert: list[tuple[int, int]] = list(to_upsert_map.items())

    # Allow client-side scheduled extra (tie-breaker) questions:
    # create TestItem rows for new question ids so server-side scoring includes them.
    extra_qids = [qid for qid, _v in to_upsert if qid not in item_ids]
    if extra_qids:
        existing_extra = sum(1 for it in items if bool(getattr(it, "is_extra", False)))
        remaining = max(0, int(test_row.extra_max) - int(existing_extra))
        if remaining <= 0:
            raise HTTPException(status_code=400, detail="åŠ æµ‹é¢˜æ•°é‡å·²è¾¾ä¸Šé™")

        extra_qids = extra_qids[:remaining]
        has_dedicated_tie_pool = (
            db.query(Question.id)
            .filter(Question.is_active.is_(True), Question.source == "tie_breaker")
            .limit(1)
            .scalar()
            is not None
        )

        q_query = db.query(Question).filter(Question.id.in_(extra_qids), Question.is_active.is_(True))
        if has_dedicated_tie_pool:
            q_query = q_query.filter(Question.source == "tie_breaker")
        q_rows = q_query.all()
        q_by_id = {int(q.id): q for q in q_rows}

        max_pos = int(items[-1].position) if items else 0
        allowed_dims = {"EI", "SN", "TF", "JP"}
        for qid in extra_qids:
            q = q_by_id.get(int(qid))
            if not q:
                continue
            if str(q.dimension) not in allowed_dims:
                continue
            max_pos += 1
            db.add(TestItem(test_id=test_row.id, position=max_pos, question_id=int(qid), is_extra=True))
        db.commit()

        # refresh item ids after appending extras
        items = (
            db.query(TestItem)
            .filter(TestItem.test_id == test_row.id)
            .order_by(TestItem.position.asc())
            .all()
        )
        item_ids = {int(it.question_id) for it in items}

    now = datetime.now(timezone.utc)
    existing = db.query(Answer).filter(Answer.test_id == test_row.id).all()
    existing_map = {int(a.question_id): a for a in existing}

    for qid, val in to_upsert:
        if qid not in item_ids:
            continue
        if val < 1 or val > 5:
            continue
        row = existing_map.get(qid)
        if row:
            row.value = val
            row.answered_at = now
        else:
            db.add(Answer(test_id=test_row.id, question_id=qid, value=val, answered_at=now))

    db.commit()

    if intent == "finish":
        saved_ids = {
            int(qid)
            for (qid,) in db.query(Answer.question_id).filter(Answer.test_id == test_row.id).all()
        }
        missing = None
        for pos_it in (
            db.query(TestItem)
            .filter(TestItem.test_id == test_row.id)
            .order_by(TestItem.position.asc())
            .all()
        ):
            if int(pos_it.question_id) not in saved_ids:
                missing = int(pos_it.position)
                break
        if missing is not None:
            return JSONResponse({"status": "incomplete", "redirect": "/test", "missing_position": missing})
        return JSONResponse({"status": "complete", "redirect": "/finish"})

    if intent == "exit":
        return JSONResponse({"status": "exit", "redirect": "/"})

    return JSONResponse({"status": "saved"})


@router.post("/test")
def test_submit(
    request: Request,
    db: Session = Depends(get_db),
    csrf_token: str = Form(...),
    position: int = Form(...),
    question_id: int = Form(...),
    value: int | None = Form(None),
    nav: str = Form(...),
):
    _require_csrf(request, csrf_token)
    test_row = _get_test_from_cookie(request, db)

    item = (
        db.query(TestItem)
        .filter(TestItem.test_id == test_row.id, TestItem.position == int(position))
        .one_or_none()
    )
    if not item or item.question_id != int(question_id):
        raise HTTPException(status_code=400, detail="é¢˜ç›®ä½ç½®ä¸åŒ¹é…")

    if value is not None:
        v = int(value)
        if v < 1 or v > 5:
            raise HTTPException(status_code=400, detail="é€‰é¡¹ä¸åˆæ³•")

        existing = (
            db.query(Answer)
            .filter(Answer.test_id == test_row.id, Answer.question_id == int(question_id))
            .one_or_none()
        )
        if existing:
            existing.value = v
            existing.answered_at = datetime.now(timezone.utc)
        else:
            db.add(
                Answer(
                    test_id=test_row.id,
                    question_id=int(question_id),
                    value=v,
                    answered_at=datetime.now(timezone.utc),
                )
            )
        db.commit()

    if nav == "exit":
        return RedirectResponse(url="/", status_code=303)

    total = db.query(TestItem).filter(TestItem.test_id == test_row.id).count()
    if nav == "prev":
        new_pos = max(1, int(position) - 1)
        return RedirectResponse(url=f"/test?pos={new_pos}", status_code=303)
    if nav == "next":
        new_pos = int(position) + 1
        if new_pos > total:
            return RedirectResponse(url="/finish", status_code=303)
        return RedirectResponse(url=f"/test?pos={new_pos}", status_code=303)

    raise HTTPException(status_code=400, detail="æœªçŸ¥å¯¼èˆªæ“ä½œ")


def _load_test_questions(db: Session, test_id: int) -> tuple[list[TestItem], list[Question]]:
    rows = (
        db.query(TestItem, Question)
        .join(Question, Question.id == TestItem.question_id)
        .filter(TestItem.test_id == test_id)
        .order_by(TestItem.position.asc())
        .all()
    )
    items = [it for it, _ in rows]
    questions = [q for _, q in rows]
    return items, questions


def _load_answers(db: Session, test_id: int) -> dict[int, int]:
    answers = db.query(Answer).filter(Answer.test_id == test_id).all()
    return {a.question_id: int(a.value) for a in answers}


def _first_missing_position(items: list[TestItem], answer_map: dict[int, int]) -> int | None:
    for it in items:
        if it.question_id not in answer_map:
            return int(it.position)
    return None


@router.get("/finish", response_class=HTMLResponse)
def finish_page(request: Request, db: Session = Depends(get_db)):
    test_row = _get_test_from_cookie(request, db)
    items, questions = _load_test_questions(db, test_row.id)
    answer_map = _load_answers(db, test_row.id)

    missing = _first_missing_position(items, answer_map)
    if missing is not None:
        return RedirectResponse(url="/test", status_code=303)

    scoring = score_all(
        [{"id": q.id, "dimension": q.dimension, "agree_pole": q.agree_pole} for q in questions],
        answer_map,
    )
    dims = scoring["dimensions"]

    csrf, should_set = _csrf_token(request)
    response = templates.TemplateResponse(
        request,
        "finish.html",
        {
            "type_code": scoring["type"],
            "dimensions": [dims[d] for d in ["EI", "SN", "TF", "JP"]],
            "csrf_token": csrf,
        },
    )
    if should_set:
        response.set_cookie(CSRF_COOKIE, csrf, httponly=True, samesite="lax")
    return response


@router.post("/finish")
def finish_submit(
    request: Request,
    db: Session = Depends(get_db),
    csrf_token: str = Form(...),
    share_expiry: str = Form(...),
):
    _require_csrf(request, csrf_token)
    test_row = _get_test_from_cookie(request, db)

    items, questions = _load_test_questions(db, test_row.id)
    answer_map = _load_answers(db, test_row.id)
    missing = _first_missing_position(items, answer_map)
    if missing is not None:
        return RedirectResponse(url="/test", status_code=303)

    scoring = score_all(
        [{"id": q.id, "dimension": q.dimension, "agree_pole": q.agree_pole} for q in questions],
        answer_map,
    )
    dims = scoring["dimensions"]

    boundary_notes: list[str] = []
    for d in ["EI", "SN", "TF", "JP"]:
        fp = int(dims[d]["first_percent"])
        sp = int(dims[d]["second_percent"])
        if is_near_boundary(fp, threshold_gap_percent=10):
            boundary_notes.append(f"{d} æ¥è¿‘è¾¹ç•Œï¼ˆ{dims[d]['first_pole']} {fp}% / {dims[d]['second_pole']} {sp}%ï¼‰")

    delta = expiry_from_choice(share_expiry)
    now = datetime.now(timezone.utc)
    share_expires_at = None if delta is None else (now + delta)

    secret = _app_secret()
    share_token = new_url_token()

    test_row.share_token_hash = hash_token(share_token, secret=secret)
    test_row.share_expires_at = share_expires_at
    test_row.result_type = scoring["type"]
    test_row.result_json = {
        "type": scoring["type"],
        "dimensions": dims,
        "boundary_notes": boundary_notes,
    }
    test_row.status = "completed"
    test_row.completed_at = now

    db.commit()

    return RedirectResponse(url=f"/result/{share_token}", status_code=303)


@router.get("/result/{share_token}", response_class=HTMLResponse)
def result_page(request: Request, share_token: str, db: Session = Depends(get_db)):
    secret = _app_secret()
    token_hash = hash_token(share_token, secret=secret)
    test_row = (
        db.query(Test)
        .options(joinedload(Test.answers).joinedload(Answer.question))
        .filter(Test.share_token_hash == token_hash)
        .one_or_none()
    )
    if not test_row or test_row.status != "completed" or not test_row.result_json:
        raise HTTPException(status_code=404, detail="ç»“æœä¸å­˜åœ¨")

    if test_row.share_expires_at and datetime.now(timezone.utc) > _as_utc(test_row.share_expires_at):
        return templates.TemplateResponse(request, "result_expired.html", {"type_code": test_row.result_type})

    result = dict(test_row.result_json)
    type_code = result.get("type") or test_row.result_type
    dims = result.get("dimensions") or {}
    boundary_notes = result.get("boundary_notes") or []

    report = build_report_context(
        str(type_code),
        dims,
        boundary_notes=list(boundary_notes),
        answers=list(getattr(test_row, "answers", []) or []),
    )

    return templates.TemplateResponse(
        request,
        "result.html",
        {
            "type_code": type_code,
            "dimensions": [dims.get(d) for d in ["EI", "SN", "TF", "JP"] if dims.get(d)],
            "dimensions_json": json.dumps(dims, ensure_ascii=False),
            "report": report,
            "share_url": str(request.base_url)[:-1] + f"/result/{share_token}",
            "share_token": share_token,
            "result_ai_stream_url": str(request.url_for("result_ai_content", share_token=share_token)),
        },
    )


def _clean_ai_markdown(md: str) -> str:
    text = (md or "").replace("TAGS_SHORT_READ_WARNING false", "").replace("TAGS_SHORT_READ_WARNING true", "")
    # Normalize headings: remove leading spaces before #'s, and normalize space after hashes.
    text = re.sub(r"^[ \t\uFE0F\u200B\u00A0\u3000]+(#{1,6})", r"\1", text, flags=re.MULTILINE)
    text = re.sub(r"(#{1,6})[ \t\uFE0F\u200B\u00A0\u3000]+", r"\1 ", text, flags=re.MULTILINE)
    text = re.sub(r"(#{1,6} \*\*)[ \t\uFE0F\u200B\u00A0\u3000]+", r"\1", text, flags=re.MULTILINE)
    return text.strip()


def _stream_sanitize_markdown_chunks(chunks: object, *, carry_size: int = 96):
    # Best-effort sanitizer that fixes headings even when whitespace/# are split across chunks.
    # Keeps a small tail buffer to handle boundary cases.
    tail = ""

    async def _agen():
        nonlocal tail
        async for part in chunks:
            s = str(part or "")
            if not s:
                continue
            combined = tail + s
            combined = combined.replace("TAGS_SHORT_READ_WARNING false", "").replace("TAGS_SHORT_READ_WARNING true", "")
            # 1) Remove any leading whitespace before heading markers
            combined = re.sub(r"(?m)^[ \t\uFE0F\u200B\u00A0\u3000]+(#{1,6})", r"\1", combined)
            # 2) Normalize whitespace *after* hashes, including invisible unicode (VS16/ZWSP/NBSP)
            combined = re.sub(r"(?m)^(#+)[ \t\uFE0F\u200B\u00A0\u3000]+", r"\1 ", combined)
            # 3) Fix bold immediately after heading marker
            combined = re.sub(r"(?m)(#{1,6} \\*\\*)[ \t\uFE0F\u200B\u00A0\u3000]+", r"\1", combined)

            if len(combined) <= carry_size:
                tail = combined
                continue

            emit = combined[:-carry_size]
            tail = combined[-carry_size:]
            yield emit

        if tail:
            yield tail

    return _agen()


def _markdown_to_html(md: str) -> str:
    # Escape raw HTML first to avoid injection, while keeping Markdown syntax intact.
    safe_md = html.escape(md or "")
    if markdown is None:
        return "<pre>" + safe_md + "</pre>"
    try:
        return markdown.markdown(safe_md, extensions=["extra", "nl2br"])
    except Exception:
        return markdown.markdown(safe_md)


@router.api_route(
    "/result/ai_content/{share_token}",
    methods=["GET", "POST"],
    response_class=HTMLResponse,
    name="result_ai_content",
)
async def result_ai_content(request: Request, share_token: str, db: Session = Depends(get_db)):
    secret = _app_secret()
    token_hash = hash_token(share_token, secret=secret)
    test_row = (
        db.query(Test)
        .options(joinedload(Test.answers).joinedload(Answer.question))
        .filter(Test.share_token_hash == token_hash)
        .one_or_none()
    )
    if not test_row or test_row.status != "completed" or not test_row.result_json:
        return StreamingResponse(
            iter(["\n\n**âš ï¸ ç»“æœä¸å­˜åœ¨æˆ–å·²å¤±æ•ˆã€‚**\n"]),
            media_type="text/plain; charset=utf-8",
            headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
        )

    if test_row.share_expires_at and datetime.now(timezone.utc) > _as_utc(test_row.share_expires_at):
        return StreamingResponse(
            iter(["\n\n**âš ï¸ åˆ†äº«é“¾æ¥å·²è¿‡æœŸã€‚**\n"]),
            media_type="text/plain; charset=utf-8",
            headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
        )

    result = test_row.result_json or {}
    type_code = str(result.get("type") or test_row.result_type or "Unknown")
    dims: dict[str, dict] = dict(result.get("dimensions") or {})
    boundary_notes = list(result.get("boundary_notes") or [])
    answers = list(getattr(test_row, "answers", []) or [])

    def _dimensions_str() -> str:
        parts: list[str] = []
        for dim in ["EI", "SN", "TF", "JP"]:
            info = dims.get(dim) or {}
            fp = info.get("first_percent")
            sp = info.get("second_percent")
            first = info.get("first_pole")
            second = info.get("second_pole")
            if fp is None or sp is None or not first or not second:
                continue
            parts.append(f"{first}:{fp}% / {second}:{sp}%")
        return ", ".join(parts) if parts else "ç»´åº¦æ•°æ®ç¼ºå¤±"

    def _extremes_str() -> str:
        items: list[str] = []
        for idx, a in enumerate(answers, start=1):
            try:
                v = int(getattr(a, "value", 0))
            except Exception:
                continue
            if v not in (1, 5):
                continue
            q = getattr(a, "question", None)
            if not q:
                continue
            text = str(getattr(q, "text", "") or "").strip()
            dim = str(getattr(q, "dimension", "") or "").strip()
            agree = str(getattr(q, "agree_pole", "") or "").strip()
            if len(dim) == 2 and len(agree) == 1:
                opposite = dim[1] if dim[0] == agree else (dim[0] if dim[1] == agree else "?")
            else:
                opposite = "?"
            pole = agree if v == 5 else opposite
            snippet = text[:48] + ("â€¦" if len(text) > 48 else "")
            items.append(f"{idx}. [{dim}/{pole}å‘] {v}åˆ†ï¼š{snippet}")
            if len(items) >= 6:
                break
        return "ï¼›".join(items) if items else "æœªå‘ç°æ˜æ˜¾çš„æå€¼ä½œç­”ï¼ˆ1åˆ†/5åˆ†ï¼‰"

    insight_list = build_report_context(
        type_code,
        dims,
        boundary_notes=boundary_notes,
        answers=answers,
    ).get("insights", [])
    insight_list = [str(x).strip() for x in (insight_list or []) if str(x).strip()]

    tags: list[str] = []
    for dim, info in (dims or {}).items():
        try:
            gap = int(info.get("gap_percent"))
        except Exception:
            continue
        if gap < 20:
            tags.append(f"{dim}å‡è¡¡")
        elif gap > 60:
            tags.append(f"{dim}æè‡´")
    if any(getattr(a, "value", None) == 5 for a in answers):
        tags.append("ç«‹åœºåšå®š")
    if any("å°½ç®¡ä½ æ•´ä½“åå‘" in s for s in insight_list):
        tags.append("åå·®å‘åŠ›")
    tags = tags[:6]

    dimensions_str = _dimensions_str()
    extreme_traits = _extremes_str()
    dynamic_insights = "ï¼›".join(insight_list[:3]) if insight_list else "æš‚æ— åŠ¨æ€æ´å¯Ÿ"
    dynamic_tags = "åŠ¨æ€æ ‡ç­¾ï¼š" + (", ".join([f"[{t}]" for t in tags]) if tags else "[ç¨³å®šä½œç­”]")

    user_profile_context = f"""
ç”¨æˆ·MBTIç±»å‹ï¼š{type_code}
ã€ç»´åº¦æ•°æ®ã€‘ï¼š{dimensions_str}
ã€æå€¼ç‰¹è´¨ã€‘ï¼š{extreme_traits}
ã€è¡Œä¸ºæ ‡ç­¾ã€‘ï¼š{dynamic_tags}
ã€åŠ¨æ€æ´å¯Ÿã€‘ï¼š{dynamic_insights}
è¯·ç»¼åˆä¸Šè¿°æ•°æ®ï¼Œå¿½ç•¥åˆ»æ¿å°è±¡ï¼Œè¿˜åŸä¸€ä¸ªé²œæ´»çš„äººã€‚
""".strip()

    system_prompt = f"""
ä½ æ˜¯ä¸€ä½æ´å¯Ÿäººæ€§å¹½æš—ä¸å…‰è¾‰çš„å¿ƒç†å­¦å¤§å¸ˆï¼Œæ­£åœ¨ä½¿ç”¨ DeepSeek-V3.2 æ¨¡å‹è¿›è¡Œæ·±åº¦ä¾§å†™ã€‚
{user_profile_context}

ã€æŒ‡ä»¤ã€‘
1. ä½ çš„è¯­è¨€è¦åƒæ‰‹æœ¯åˆ€ä¸€æ ·ç²¾å‡†ï¼Œå‰¥å¼€ç”¨æˆ·çš„ç¤¾ä¼šé¢å…·ï¼Œç›´æŒ‡å†…å¿ƒæ·±å¤„çš„çŸ›ç›¾ä¸æ¸´æœ›ã€‚
2. ç»“åˆç»™å‡ºçš„ç»´åº¦æ•°æ®å’Œæå€¼ç‰¹è´¨è¿›è¡Œæ¨ç†ï¼Œä¸è¦åªç½—åˆ—ä¼˜ç¼ºç‚¹ã€‚
3. ä¸¥ç¦è¾“å‡ºä»»ä½•å¼€åœºç™½ï¼Œä¸¥ç¦ä½¿ç”¨ä»£ç å—ã€‚
4. ã€æ’ç‰ˆä¸¥æ ¼è¦æ±‚ã€‘ï¼š
   - æ‰€æœ‰æ ‡é¢˜ï¼ˆ###ï¼‰å¿…é¡»**é¡¶æ ¼ä¹¦å†™**ï¼Œä¸¥ç¦åœ¨å‰é¢åŠ ç©ºæ ¼ï¼Œç¡®ä¿å·¦å¯¹é½ã€‚
   - **å…³é”®æ ¼å¼**ï¼šæ ‡é¢˜çš„äº•å·ä¸æ–‡å­—ä¹‹é—´**åªèƒ½æœ‰ä¸€ä¸ªç©ºæ ¼**ï¼ˆä¾‹å¦‚ `### æ ‡é¢˜`ï¼‰ï¼Œä¸¥ç¦å‡ºç°ä¸¤ä¸ªç©ºæ ¼æˆ–å…¨è§’ç©ºæ ¼ã€‚
   - è¯·åŠ¡å¿…ä½¿ç”¨ Markdown åŠ ç²—è¯­æ³•ï¼ˆå¦‚ **å…³é”®ç‰¹è´¨**ï¼‰é«˜äº®æ–‡ä¸­é‚£äº›ç›´å‡»çµé­‚ã€åç›´è§‰æˆ–æœ€å…·å†²å‡»åŠ›çš„çŸ­å¥ï¼Œæ¯æ®µè‡³å°‘åŒ…å« 1-2 å¤„é«˜äº®ã€‚

ã€è¾“å‡ºæ¨¡ç‰ˆã€‘
### ï¸ çµé­‚åº•è‰²
(ç”¨ä¸€ä¸ªå¸¦æœ‰ç°åº¦è‰²å½©çš„æ„è±¡ï¼Œå¦‚â€œ**æš´é£é›¨ä¸­çš„ç¯å¡”**â€ï¼Œæè¿°è¯¥äººæ ¼æœ€åº•å±‚çš„æ ¸å¿ƒé©±åŠ¨åŠ›ã€‚çº¦ 100 å­—)

###  é•œåƒä¸é˜´å½±
(æŒ‡å‡ºç”¨æˆ·å¸¸å¸¸æ¬ºéª—è‡ªå·±çš„ä¸€ç‚¹ï¼Œä»¥åŠå¤–ç•Œè¯¯è§£æœ€æ·±çš„ä¸€ç‚¹ã€‚ç”¨â€œä¸–äººçš†ä»¥ä¸º...ï¼Œæ®Šä¸çŸ¥...â€çš„å¥å¼ã€‚çº¦ 150 å­—)

###  ç»™ä¼¤å£çš„è¯—
(é’ˆå¯¹è¯¥äººæ ¼æœ€å®¹æ˜“å—æŒ«çš„è½¯è‚‹ï¼Œå†™ä¸€æ®µæ²»æ„ˆä¸”å……æ»¡åŠ›é‡çš„çŸ­å¥ã€‚çº¦ 80 å­—)
""".strip()

    user_prompt = f"æˆ‘çš„ MBTI ç±»å‹æ˜¯ï¼š{type_code}ã€‚è¯·å¼€å§‹ä½ çš„æ·±åº¦è§£è¯»ã€‚"

    api_key = os.getenv("MBTI_AI_API_KEY")
    base_url = os.getenv("MBTI_AI_BASE_URL", "https://api.siliconflow.cn/v1")
    model = os.getenv("MBTI_AI_MODEL", "deepseek-ai/DeepSeek-V3.2")

    async def generator_raw():
        if not api_key:
            yield "\n\n**âŒ AI ç”Ÿæˆå¤±è´¥**\n\né”™è¯¯ï¼šç³»ç»Ÿæœªé…ç½® MBTI_AI_API_KEY\n"
            return
        if AsyncOpenAI is None:
            yield "\n\n**âŒ AI ç”Ÿæˆå¤±è´¥**\n\né”™è¯¯ï¼šOpenAI SDK ä¸å¯ç”¨\n"
            return

        client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        try:
            stream = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                stream=True,
                timeout=60.0,
            )

            async for chunk in stream:
                if await request.is_disconnected():
                    break
                try:
                    choices = getattr(chunk, "choices", None)
                    if not choices:
                        continue
                    delta = getattr(choices[0], "delta", None)
                    if not delta:
                        continue
                    content = getattr(delta, "content", None)
                    if not content:
                        continue
                    yield str(content)
                except Exception:
                    continue
        except Exception as e:
            err = str(e).strip()
            if len(err) > 240:
                err = err[:240] + "..."
            yield f"\n\n**âŒ AI ç”Ÿæˆå¤±è´¥**\n\né”™è¯¯ï¼š{err}\n"
        finally:
            try:
                await client.close()
            except Exception:
                pass

    return StreamingResponse(
        _stream_sanitize_markdown_chunks(generator_raw()),
        media_type="text/plain; charset=utf-8",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
    )


def _rpg_radar_from_dimensions(dims: dict[str, object]) -> list[int]:
    def clamp(v: float) -> int:
        return int(max(0, min(100, round(v))))

    def pole_percent(dim_key: str, pole: str) -> int:
        raw = dims.get(dim_key)
        if not isinstance(raw, dict):
            return 50
        first_pole = str(raw.get("first_pole") or "")
        second_pole = str(raw.get("second_pole") or "")
        first_percent = raw.get("first_percent")
        second_percent = raw.get("second_percent")
        try:
            fp = int(first_percent) if first_percent is not None else 50
            sp = int(second_percent) if second_percent is not None else 50
        except Exception:
            fp, sp = 50, 50

        if first_pole == pole:
            return max(0, min(100, fp))
        if second_pole == pole:
            return max(0, min(100, sp))
        return 50

    e = pole_percent("EI", "E")
    s = pole_percent("SN", "S")
    n = pole_percent("SN", "N")
    t = pole_percent("TF", "T")
    f = pole_percent("TF", "F")
    j = pole_percent("JP", "J")
    p = pole_percent("JP", "P")

    creativity = clamp(n * 0.8 + p * 0.2)
    execution = clamp(j * 0.8 + s * 0.2)
    logic = clamp(t)
    empathy = clamp(f)
    adaptability = clamp(p)
    social = clamp(e)

    return [creativity, execution, logic, empathy, adaptability, social]


def get_conflict_pair(dimensions: dict[str, int]) -> tuple[str, str]:
    pairs = [("E", "I"), ("S", "N"), ("T", "F"), ("J", "P")]
    best_pair: tuple[str, str] = ("T", "F")
    best_gap = 10**9
    for a, b in pairs:
        va = int(dimensions.get(a, 50))
        vb = int(dimensions.get(b, 50))
        gap = abs(va - vb)
        if gap < best_gap:
            best_gap = gap
            best_pair = (a, b)
    return best_pair


def get_fallback_data(error_msg: str) -> dict[str, object]:
    safe_err = (error_msg or "").strip()
    if len(safe_err) > 220:
        safe_err = safe_err[:220] + "..."

    return {
        "manual": {
            "do_list": ["(ç³»ç»Ÿ) AI ç”Ÿæˆå¤±è´¥", "è¯·æ£€æŸ¥åç«¯æ—¥å¿—", "é”™è¯¯è¯¦æƒ…è§ä¸‹æ–¹"],
            "dont_list": ["ä¸è¦æƒŠæ…Œ", "ä¸è¦é¢‘ç¹åˆ·æ–°", "ä¸è¦æ³„éœ²å¯†é’¥ä¿¡æ¯"],
            "recharge": f"é”™è¯¯è¿½è¸ª: {safe_err}",
        },
        "war": {
            "title": "ç³»ç»Ÿå¼‚å¸¸ vs è°ƒè¯•æ¨¡å¼",
            "description": (
                f"API è°ƒç”¨æˆ–è§£æå¤±è´¥ã€‚å…·ä½“åŸå› ï¼š{safe_err}ã€‚"
                "è¯·æ£€æŸ¥ API Key ä½™é¢ã€ç½‘ç»œè¿æ¥ã€Base URL æˆ– JSON æ ¼å¼çº¦æŸã€‚"
            ),
        },
        "relationships": {
            "soulmate": {"mbti": "????", "role": "æœªçŸ¥", "desc": f"(ç³»ç»Ÿ) ç”Ÿæˆå¤±è´¥ï¼š{safe_err}"},
            "nemesis": {"mbti": "????", "role": "æœªçŸ¥", "desc": f"(ç³»ç»Ÿ) ç”Ÿæˆå¤±è´¥ï¼š{safe_err}"},
        },
        "character": {
            "name": "æœªçŸ¥",
            "source": "æœªçŸ¥",
            "quote": "ï¼ˆç³»ç»Ÿï¼‰æš‚æ— å°è¯",
            "desc": f"(ç³»ç»Ÿ) ç”Ÿæˆå¤±è´¥ï¼š{safe_err}",
        },
    }


def _extract_json_object(text: str) -> str | None:
    s = (text or "").strip()
    if not s:
        return None
    if s.startswith("```"):
        s = s.strip("`").strip()
    start = s.find("{")
    end = s.rfind("}")
    if start == -1 or end == -1 or end <= start:
        return None
    return s[start : end + 1]


def _normalize_letter_dimensions(dimensions_obj: object) -> dict[str, int]:
    # Accept either:
    # 1) {"E":60,"I":40,...} or
    # 2) {"EI":{"first_pole":"E","first_percent":60,"second_pole":"I","second_percent":40}, ...}
    out: dict[str, int] = {}
    if isinstance(dimensions_obj, dict):
        # direct letters
        letter_keys = {"E", "I", "S", "N", "T", "F", "J", "P"}
        if any(k in dimensions_obj for k in letter_keys):
            for k in letter_keys:
                v = dimensions_obj.get(k)
                try:
                    out[k] = max(0, min(100, int(v)))
                except Exception:
                    out[k] = 50
        else:
            for dim_key in ("EI", "SN", "TF", "JP"):
                raw = dimensions_obj.get(dim_key)
                if not isinstance(raw, dict):
                    continue
                try:
                    fpole = str(raw.get("first_pole"))
                    spole = str(raw.get("second_pole"))
                    fp = int(raw.get("first_percent"))
                    sp = int(raw.get("second_percent"))
                except Exception:
                    continue
                out[fpole] = max(0, min(100, fp))
                out[spole] = max(0, min(100, sp))

    # Ensure all exist.
    for k in ("E", "I", "S", "N", "T", "F", "J", "P"):
        out.setdefault(k, 50)
    return out


def _rpg_radar_from_letter_dimensions(dimensions: dict[str, int]) -> list[int]:
    def clamp(v: float) -> int:
        return int(max(0, min(100, round(v))))

    e = int(dimensions.get("E", 50))
    s = int(dimensions.get("S", 50))
    n = int(dimensions.get("N", 50))
    t = int(dimensions.get("T", 50))
    f = int(dimensions.get("F", 50))
    j = int(dimensions.get("J", 50))
    p = int(dimensions.get("P", 50))

    creativity = clamp(n * 0.8 + p * 0.2)
    execution = clamp(j * 0.8 + s * 0.2)
    logic = clamp(t)
    empathy = clamp(f)
    adaptability = clamp(p)
    social = clamp(e)
    return [creativity, execution, logic, empathy, adaptability, social]


def _analysis_core(mbti_type: str, dimensions_json: str) -> dict[str, object]:
    try:
        parsed = json.loads(dimensions_json)
    except Exception:
        parsed = {}

    letter_dims = _normalize_letter_dimensions(parsed)
    conflict_pair = get_conflict_pair(letter_dims)
    val1 = int(letter_dims.get(conflict_pair[0], 50))
    val2 = int(letter_dims.get(conflict_pair[1], 50))

    # Versus bar widths must sum to 100.
    total = max(1, val1 + val2)
    left_percent = int(round(val1 / total * 100))
    right_percent = 100 - left_percent
    if val2 > val1:
        conflict_pair = (conflict_pair[1], conflict_pair[0])
        val1, val2 = val2, val1
        left_percent, right_percent = right_percent, left_percent

    radar_data = _rpg_radar_from_letter_dimensions(letter_dims)

    return {
        "mbti_type": mbti_type,
        "dimensions_json": dimensions_json,
        "letter_dims": letter_dims,
        "conflict_pair": conflict_pair,
        "val1": val1,
        "val2": val2,
        "war_left_pole": conflict_pair[0],
        "war_left_percent": left_percent,
        "war_right_pole": conflict_pair[1],
        "war_right_percent": right_percent,
        "radar_data": radar_data,
    }


@router.get("/analysis", response_class=HTMLResponse)
def analysis_page_get(
    request: Request,
    db: Session = Depends(get_db),
    type_code: str = Query("", alias="type"),
    dimensions: str | None = Query(None),
):
    if not type_code or not dimensions:
        return RedirectResponse(url="/", status_code=303)

    core = _analysis_core(type_code, dimensions)
    analysis_card_url = str(request.url_for("analysis_card_content"))

    return templates.TemplateResponse(
        request,
        "analysis.html",
        {
            "type_code": type_code,
            "mbti_type": type_code,
            "radar_data_json": json.dumps(core["radar_data"], ensure_ascii=False),
            "analysis_card_url": analysis_card_url,
            "analysis_card_payload_json": json.dumps({"type": type_code, "dimensions": dimensions}, ensure_ascii=False),
        },
    )


@router.post("/analysis", response_class=HTMLResponse)
def analysis_page_post(
    request: Request,
    db: Session = Depends(get_db),
    type_code: str = Form("", alias="type"),
    dimensions: str = Form(""),
):
    if not type_code or not dimensions:
        return RedirectResponse(url="/", status_code=303)

    core = _analysis_core(type_code, dimensions)
    analysis_card_url = str(request.url_for("analysis_card_content"))

    return templates.TemplateResponse(
        request,
        "analysis.html",
        {
            "type_code": type_code,
            "mbti_type": type_code,
            "radar_data_json": json.dumps(core["radar_data"], ensure_ascii=False),
            "analysis_card_url": analysis_card_url,
            "analysis_card_payload_json": json.dumps({"type": type_code, "dimensions": dimensions}, ensure_ascii=False),
        },
    )


@router.post("/analysis/content_card", response_class=HTMLResponse, name="analysis_card_content")
async def analysis_card_content(request: Request, db: Session = Depends(get_db)):
    try:
        body = await request.json()
        data = body if isinstance(body, dict) else {}
    except Exception:
        data = {}

    mbti_type = str(data.get("type") or "").strip()
    raw_dimensions = data.get("dimensions")

    if isinstance(raw_dimensions, str):
        dimensions_json = raw_dimensions
    elif raw_dimensions is None:
        dimensions_json = "{}"
    else:
        try:
            dimensions_json = json.dumps(raw_dimensions, ensure_ascii=False)
        except Exception:
            dimensions_json = "{}"

    if not mbti_type:
        fun_data = get_fallback_data("ç¼ºå°‘ type å‚æ•°")
        return templates.TemplateResponse(
            request,
            "partials/analysis_content.html",
            {
                "fun_data": fun_data,
                "conflict_pair": "T vs F",
                "war_left_pole": "T",
                "war_left_percent": 50,
                "war_right_pole": "F",
                "war_right_percent": 50,
            },
        )

    core = _analysis_core(mbti_type, dimensions_json)
    conflict_pair = core["conflict_pair"]
    val1 = int(core["val1"])
    val2 = int(core["val2"])
    letter_dims = core["letter_dims"]

    prompt = f"""
ç”¨æˆ·MBTI: {mbti_type}
å„ç»´åº¦åˆ†å€¼: {json.dumps(letter_dims, ensure_ascii=False)}
å†…å¿ƒæœ€å†²çªçš„ç»´åº¦: {conflict_pair[0]} (score: {val1}) vs {conflict_pair[1]} (score: {val2}) - åˆ†å€¼æåº¦æ¥è¿‘ã€‚

è¯·åŸºäºä»¥ä¸Šæ•°æ®ï¼Œç”Ÿæˆï¼š
1) â€œç”¨æˆ·ä½¿ç”¨è¯´æ˜ä¹¦â€
2) â€œå†…å¿ƒç»´åº¦æˆ˜äº‰â€
3) â€œå‘½å®šç¾ç»Šâ€ï¼ˆæœ€ä½³ä¼´ä¾£ soulmate + æœ€å¤§å¤©æ•Œ nemesisï¼‰
4) â€œçµé­‚æŠ•å½±â€ï¼ˆæœ€åƒçš„å½±è§†/åŠ¨æ¼«è§’è‰² characterï¼‰
å¿…é¡»ä¸¥æ ¼è¾“å‡ºçº¯ JSON æ ¼å¼ï¼Œæ—  Markdownï¼š
{{
    "manual": {{
        "do_list": ["3ä¸ªè®©è¯¥ç”¨æˆ·æ„Ÿåˆ°è¢«ç†è§£çš„è¡Œä¸º"],
        "dont_list": ["3ä¸ªè¯¥ç”¨æˆ·çš„ç»å¯¹é›·åŒº"],
        "recharge": "1ä¸ªå…·ä½“çš„å¿«é€Ÿå›è¡€æ–¹å¼"
    }},
    "war": {{
        "title": "å†²çªç»´åº¦çš„å…·è±¡åŒ–æ¯”å–» (å¦‚ï¼šç†æ€§çš„æš´å› vs æ„Ÿæ€§çš„è¯—äºº)",
        "description": "æ·±åº¦åˆ†æè¿™ç§çº ç»“å¸¦æ¥çš„å›°æ‰°ä¸ä¼˜åŠ¿ã€‚"
    }},
    "relationships": {{
        "soulmate": {{
            "mbti": "XXXX",
            "role": "è§’è‰²ç§°å‘¼",
            "desc": "ä¸€å¥è¯è§£é‡Šä¸ºä»€ä¹ˆä½ ä»¬æ˜¯çµé­‚ä¼´ä¾£"
        }},
        "nemesis": {{
            "mbti": "XXXX",
            "role": "è§’è‰²ç§°å‘¼",
            "desc": "ä¸€å¥è¯è§£é‡Šä¸ºä»€ä¹ˆä½ ä»¬ç›¸çˆ±ç›¸æ€æˆ–äº’ç›¸çœ‹ä¸é¡ºçœ¼"
        }}
    }},
    "character": {{
        "name": "è§’è‰²å",
        "source": "ä½œå“å",
        "quote": "ç»å…¸å°è¯",
        "desc": "ç®€çŸ­åˆ†æç”¨æˆ·ä¸è¯¥è§’è‰²çš„æ€§æ ¼ç›¸ä¼¼ç‚¹"
    }}
}}
""".strip()

    fun_data: dict[str, object]
    try:
        if AsyncOpenAI is None:
            raise RuntimeError("OpenAI SDK æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")

        api_key = os.getenv("MBTI_AI_API_KEY")
        if not api_key:
            raise RuntimeError("æœªé…ç½® MBTI_AI_API_KEY")

        base_url = os.getenv("MBTI_AI_BASE_URL", "https://api.siliconflow.cn/v1")
        model = os.getenv("MBTI_AI_MODEL", "deepseek-ai/DeepSeek-V3.2")

        client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        try:
            resp = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ å¿…é¡»åªè¾“å‡ºçº¯ JSONã€‚"},
                    {"role": "user", "content": prompt},
                ],
                stream=False,
                timeout=60.0,
            )
        finally:
            try:
                await client.close()
            except Exception:
                pass

        content = ""
        try:
            content = resp.choices[0].message.content or ""
        except Exception as e:
            raise RuntimeError(f"AI å“åº”ä¸ºç©ºæˆ–ç»“æ„å¼‚å¸¸: {e}") from e

        try:
            fun_data_obj = json.loads(content)
        except Exception:
            extracted = _extract_json_object(content)
            if not extracted:
                raise ValueError("AI æœªè¿”å›å¯è§£æçš„ JSON å¯¹è±¡")
            fun_data_obj = json.loads(extracted)

        if not isinstance(fun_data_obj, dict):
            raise ValueError("AI JSON é¡¶å±‚ä¸æ˜¯å¯¹è±¡")

        # --- Sanitizer: tolerate common schema mistakes from the model ---
        def _ensure_str(v: object, default: str = "") -> str:
            if v is None:
                return default
            if isinstance(v, str):
                return v.strip()
            return str(v).strip()

        manual = fun_data_obj.get("manual")
        if not isinstance(manual, dict):
            manual = {}
        do_list = manual.get("do_list")
        dont_list = manual.get("dont_list")
        manual["do_list"] = do_list if isinstance(do_list, list) else []
        manual["dont_list"] = dont_list if isinstance(dont_list, list) else []
        manual["recharge"] = _ensure_str(manual.get("recharge"), default="ï¼ˆç”Ÿæˆå¤±è´¥ï¼‰")

        war = fun_data_obj.get("war")
        if not isinstance(war, dict):
            war = {}
        war["title"] = _ensure_str(war.get("title"), default="ï¼ˆç”Ÿæˆå¤±è´¥ï¼‰")
        war["description"] = _ensure_str(war.get("description"), default="ï¼ˆç”Ÿæˆå¤±è´¥ï¼‰")

        relationships = fun_data_obj.get("relationships")
        if isinstance(relationships, str):
            relationships = {}
        if not isinstance(relationships, dict):
            relationships = {}

        for key in ("soulmate", "nemesis"):
            v = relationships.get(key)
            if isinstance(v, str):
                relationships[key] = {"mbti": "UNK", "role": "æœªçŸ¥", "desc": v}
            elif not isinstance(v, dict):
                relationships[key] = {"mbti": "UNK", "role": "æœªçŸ¥", "desc": "ï¼ˆç”Ÿæˆå¤±è´¥ï¼‰"}
            else:
                relationships[key] = {
                    "mbti": _ensure_str(v.get("mbti"), default="UNK"),
                    "role": _ensure_str(v.get("role"), default="æœªçŸ¥"),
                    "desc": _ensure_str(v.get("desc"), default="ï¼ˆç”Ÿæˆå¤±è´¥ï¼‰"),
                }

        character = fun_data_obj.get("character")
        if isinstance(character, str):
            character = {"name": "æœªçŸ¥", "source": "æœªçŸ¥", "quote": "â€¦", "desc": character}
        if not isinstance(character, dict):
            character = {}
        character = {
            "name": _ensure_str(character.get("name"), default="æœªçŸ¥"),
            "source": _ensure_str(character.get("source"), default="æœªçŸ¥"),
            "quote": _ensure_str(character.get("quote"), default="â€¦"),
            "desc": _ensure_str(character.get("desc"), default="ï¼ˆç”Ÿæˆå¤±è´¥ï¼‰"),
        }

        fun_data_obj["manual"] = manual
        fun_data_obj["war"] = war
        fun_data_obj["relationships"] = relationships
        fun_data_obj["character"] = character
        # ---------------------------------------------------------------

        fun_data = fun_data_obj
    except Exception as e:
        fun_data = get_fallback_data(str(e))

    return templates.TemplateResponse(
        request,
        "partials/analysis_content.html",
        {
            "fun_data": fun_data,
            "conflict_pair": f"{conflict_pair[0]} vs {conflict_pair[1]}",
            "war_left_pole": core["war_left_pole"],
            "war_left_percent": int(core["war_left_percent"]),
            "war_right_pole": core["war_right_pole"],
            "war_right_percent": int(core["war_right_percent"]),
        },
    )


@router.api_route("/analysis/content", methods=["GET", "POST"], response_class=HTMLResponse, name="analysis_async_content")
async def analysis_async_content(
    request: Request,
    db: Session = Depends(get_db),
    type_code: str = Query("", alias="type"),
    dimensions: str | None = Query(None),
):
    data: dict[str, object] = {}
    if request.method == "POST":
        try:
            body = await request.json()
            if isinstance(body, dict):
                data = body
        except Exception:
            data = {}

    mbti_type = str(data.get("type") or type_code or "")
    raw_dimensions = data.get("dimensions") if "dimensions" in data else dimensions

    if isinstance(raw_dimensions, str):
        dimensions_json = raw_dimensions
    elif raw_dimensions is None:
        dimensions_json = "{}"
    else:
        try:
            dimensions_json = json.dumps(raw_dimensions, ensure_ascii=False)
        except Exception:
            dimensions_json = "{}"

    if not mbti_type or not dimensions_json:
        return HTMLResponse("", status_code=400)

    core = _analysis_core(mbti_type, dimensions_json)
    conflict_pair = core["conflict_pair"]
    val1 = int(core["val1"])
    val2 = int(core["val2"])
    letter_dims = core["letter_dims"]

    prompt = f"""
ä½ æ˜¯ä¸€ä½é£æ ¼é²œæ˜ä½†å…‹åˆ¶çš„å¿ƒç†åˆ†æå¸ˆã€‚è¯·ç›´æ¥è¾“å‡º Markdownï¼ˆä¸è¦ä»£ç å—ï¼Œä¸è¦å¼€åœºç™½ï¼‰ï¼Œç»“æ„å¦‚ä¸‹ï¼š

### âœ… æ­£ç¡®é¥²å…»æŒ‡å—
- (3-5 æ¡å¯æ‰§è¡Œå»ºè®®)

### âŒ ç¦å¿Œæ“ä½œé¢„è­¦
- (3-5 æ¡ç»å¯¹é›·åŒº)

### ğŸ”‹ å¿«é€Ÿå……ç”µæ–¹å¼
(1 å¥è¯ï¼Œ<=25 å­—)

### âš”ï¸ ç»´åº¦æˆ˜äº‰ï¼šä¸€å¥è¯æ¯”å–»æ ‡é¢˜
(80-140 å­—ï¼Œå†™å‡ºå†…è€—çš„å›°æ‰°ä¸ä¼˜åŠ¿ï¼Œå¹¶ç»™å‡ºæ¸©æŸ”çš„å’Œè§£å»ºè®®)

ç”¨æˆ·MBTI: {mbti_type}
å„ç»´åº¦åˆ†å€¼: {json.dumps(letter_dims, ensure_ascii=False)}
å†…å¿ƒæœ€å†²çªçš„ç»´åº¦: {conflict_pair[0]} (score: {val1}) vs {conflict_pair[1]} (score: {val2}) - åˆ†å€¼æåº¦æ¥è¿‘ã€‚
""".strip()

    api_key = os.getenv("MBTI_AI_API_KEY")
    base_url = os.getenv("MBTI_AI_BASE_URL", "https://api.siliconflow.cn/v1")
    model = os.getenv("MBTI_AI_MODEL", "deepseek-ai/DeepSeek-V3.2")

    async def generator():
        if not api_key:
            yield "\n\n**âŒ AI ç”Ÿæˆå¤±è´¥**\n\né”™è¯¯ï¼šç³»ç»Ÿæœªé…ç½® MBTI_AI_API_KEY\n"
            return
        if AsyncOpenAI is None:
            yield "\n\n**âŒ AI ç”Ÿæˆå¤±è´¥**\n\né”™è¯¯ï¼šOpenAI SDK ä¸å¯ç”¨\n"
            return

        client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        try:
            stream = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You output Markdown only."},
                    {"role": "user", "content": prompt},
                ],
                stream=True,
                timeout=60.0,
            )

            async for chunk in stream:
                if await request.is_disconnected():
                    break
                try:
                    choices = getattr(chunk, "choices", None)
                    if not choices:
                        continue
                    delta = getattr(choices[0], "delta", None)
                    if not delta:
                        continue
                    content = getattr(delta, "content", None)
                    if not content:
                        continue
                    yield str(content)
                except Exception:
                    continue
        except Exception as e:
            err = str(e).strip()
            if len(err) > 240:
                err = err[:240] + "..."
            yield f"\n\n**âŒ AI ç”Ÿæˆå¤±è´¥**\n\né”™è¯¯ï¼š{err}\n"
        finally:
            try:
                await client.close()
            except Exception:
                pass

    return StreamingResponse(
        generator(),
        media_type="text/plain; charset=utf-8",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
    )


@router.get("/result/ai_stream/{share_token}")
async def ai_stream(request: Request, share_token: str, db: Session = Depends(get_db)):
    # æœ€ç»ˆæ•´åˆç‰ˆï¼šçµé­‚ä¾§å†™æç¤ºè¯ + ç´¯åŠ æµå¼è¾“å‡º + é˜²é‡è¿
    async def event_generator():
        client = None

        # 1) é˜²æ— é™é‡è¿ï¼šæ–­å¼€åç­‰å¾… 24 å°æ—¶å†é‡è¿
        yield "retry: 86400000\n\n"

        try:
            def local_app_secret() -> str:
                # å…¼å®¹å†å²å‘½åï¼šä¼˜å…ˆ MBTI_APP_SECRETï¼Œå…¶æ¬¡ APP_SECRET
                return os.getenv("MBTI_APP_SECRET") or os.getenv("APP_SECRET", "secret")

            def local_hash_token(token: str, secret: str) -> str:
                # ä¸ app.services.tokens.hash_token ä¸€è‡´ï¼šsha256(secret + token)
                digest = hashlib.sha256()
                digest.update(secret.encode("utf-8"))
                digest.update(token.encode("utf-8"))
                return digest.hexdigest()

            yield "data: [é˜¶æ®µ1] è¿æ¥å·²å»ºç«‹ï¼Œå¼€å§‹éªŒè¯...\n\n"

            secret = local_app_secret()
            token_hash = local_hash_token(share_token, secret)
            test_row = (
                db.query(Test)
                .options(joinedload(Test.answers).joinedload(Answer.question))
                .filter(Test.share_token_hash == token_hash)
                .first()
            )
            if not test_row:
                yield "data: <span class='text-red-500'>âš ï¸ é“¾æ¥å·²å¤±æ•ˆï¼Œæ— æ³•è·å–æµ‹è¯•è®°å½•ã€‚</span>\n\n"
                return

            result = test_row.result_json or {}
            type_code = result.get("type", "Unknown")

            base_url = os.getenv("MBTI_AI_BASE_URL", "https://api.siliconflow.cn/v1")
            api_key = os.getenv("MBTI_AI_API_KEY")
            model = os.getenv("MBTI_AI_MODEL", "deepseek-ai/DeepSeek-V3.2")

            if not api_key:
                yield "data: âš ï¸ ç³»ç»Ÿæœªé…ç½® AI API Keyï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚\n\n"
                return

            if AsyncOpenAI is None:
                yield "data: <span class='text-red-500'>âŒ ç³»ç»Ÿé”™è¯¯: OpenAI SDK ä¸å¯ç”¨</span>\n\n"
                return

            yield f"data: [é˜¶æ®µ2] å‡†å¤‡è¯·æ±‚ AIï¼ˆ{html.escape(str(model))}ï¼‰...\n\n"
            client = AsyncOpenAI(api_key=api_key, base_url=base_url)

            # --- æ„å»ºâ€œå…¨æ¯ç”»åƒâ€æ•°æ® ---
            dims: dict[str, dict] = dict(result.get("dimensions") or {})
            boundary_notes = list(result.get("boundary_notes") or [])

            def _dimensions_str() -> str:
                parts: list[str] = []
                for dim in ["EI", "SN", "TF", "JP"]:
                    info = dims.get(dim) or {}
                    fp = info.get("first_percent")
                    sp = info.get("second_percent")
                    first = info.get("first_pole")
                    second = info.get("second_pole")
                    if first and second and fp is not None and sp is not None:
                        parts.append(f"{first}:{int(fp)}% / {second}:{int(sp)}%")
                return ", ".join(parts) if parts else "æš‚æ— ç»´åº¦ç™¾åˆ†æ¯”æ•°æ®"

            def _extremes_str() -> str:
                items: list[str] = []
                for idx, a in enumerate(list(getattr(test_row, "answers", []) or []), start=1):
                    try:
                        v = int(getattr(a, "value", 0))
                    except Exception:
                        continue
                    if v not in (1, 5):
                        continue
                    q = getattr(a, "question", None)
                    if not q:
                        continue
                    text = str(getattr(q, "text", "") or "").strip()
                    dim = str(getattr(q, "dimension", "") or "").strip()
                    agree = str(getattr(q, "agree_pole", "") or "").strip()
                    if len(dim) == 2 and len(agree) == 1:
                        opposite = dim[1] if dim[0] == agree else (dim[0] if dim[1] == agree else "?")
                    else:
                        opposite = "?"
                    pole = agree if v == 5 else opposite
                    snippet = text[:48] + ("â€¦" if len(text) > 48 else "")
                    items.append(f"{idx}. [{dim}/{pole}å‘] {v}åˆ†ï¼š{snippet}")
                    if len(items) >= 6:
                        break
                return "ï¼›".join(items) if items else "æœªå‘ç°æ˜æ˜¾çš„æå€¼ä½œç­”ï¼ˆ1åˆ†/5åˆ†ï¼‰"

            answers = list(getattr(test_row, "answers", []) or [])
            insight_list = build_report_context(
                type_code,
                dims,
                boundary_notes=boundary_notes,
                answers=answers,
            ).get("insights", [])
            insight_list = [str(x).strip() for x in (insight_list or []) if str(x).strip()]

            tags: list[str] = []
            for dim, info in (dims or {}).items():
                try:
                    gap = int(info.get("gap_percent"))
                except Exception:
                    continue
                if gap < 20:
                    tags.append(f"{dim}å‡è¡¡")
                elif gap > 60:
                    tags.append(f"{dim}æè‡´")
            if any(getattr(a, "value", None) == 5 for a in answers):
                tags.append("ç«‹åœºåšå®š")
            if any("å°½ç®¡ä½ æ•´ä½“åå‘" in s for s in insight_list):
                tags.append("åå·®å‘åŠ›")
            tags = tags[:6]

            dimensions_str = _dimensions_str()
            extreme_traits = _extremes_str()
            dynamic_insights = "ï¼›".join(insight_list[:3]) if insight_list else "æš‚æ— åŠ¨æ€æ´å¯Ÿ"
            dynamic_tags = "åŠ¨æ€æ ‡ç­¾ï¼š" + (", ".join([f"[{t}]" for t in tags]) if tags else "[ç¨³å®šä½œç­”]")

            user_profile_context = f"""
ç”¨æˆ·MBTIç±»å‹ï¼š{type_code}
ã€ç»´åº¦æ•°æ®ã€‘ï¼š{dimensions_str}
ã€æå€¼ç‰¹è´¨ã€‘ï¼š{extreme_traits}
ã€è¡Œä¸ºæ ‡ç­¾ã€‘ï¼š{dynamic_tags}
ã€åŠ¨æ€æ´å¯Ÿã€‘ï¼š{dynamic_insights}
è¯·ç»¼åˆä¸Šè¿°æ•°æ®ï¼Œå¿½ç•¥åˆ»æ¿å°è±¡ï¼Œè¿˜åŸä¸€ä¸ªé²œæ´»çš„äººã€‚
""".strip()

            # --- æç¤ºè¯å‡çº§ï¼šæ–¹æ¡ˆ Aã€Œæ·±æ¸Šå‡è§†è€…ã€(æ ¼å¼å¯¹é½ + é‡ç‚¹åŠ ç²—) ---
            system_prompt = f"""
ä½ æ˜¯ä¸€ä½æ´å¯Ÿäººæ€§å¹½æš—ä¸å…‰è¾‰çš„å¿ƒç†å­¦å¤§å¸ˆï¼Œæ­£åœ¨ä½¿ç”¨ DeepSeek-V3.2 æ¨¡å‹è¿›è¡Œæ·±åº¦ä¾§å†™ã€‚
{user_profile_context}

ã€æŒ‡ä»¤ã€‘
1. ä½ çš„è¯­è¨€è¦åƒæ‰‹æœ¯åˆ€ä¸€æ ·ç²¾å‡†ï¼Œå‰¥å¼€ç”¨æˆ·çš„ç¤¾ä¼šé¢å…·ï¼Œç›´æŒ‡å†…å¿ƒæ·±å¤„çš„çŸ›ç›¾ä¸æ¸´æœ›ã€‚
2. ç»“åˆç»™å‡ºçš„ç»´åº¦æ•°æ®å’Œæå€¼ç‰¹è´¨è¿›è¡Œæ¨ç†ï¼Œä¸è¦åªç½—åˆ—ä¼˜ç¼ºç‚¹ã€‚
3. ä¸¥ç¦è¾“å‡ºä»»ä½•å¼€åœºç™½ï¼Œä¸¥ç¦ä½¿ç”¨ä»£ç å—ã€‚
4. ã€æ’ç‰ˆä¸¥æ ¼è¦æ±‚ã€‘ï¼š
   - æ‰€æœ‰æ ‡é¢˜ï¼ˆ###ï¼‰å¿…é¡»**é¡¶æ ¼ä¹¦å†™**ï¼Œä¸¥ç¦åœ¨å‰é¢åŠ ç©ºæ ¼ï¼Œç¡®ä¿å·¦å¯¹é½ã€‚
   - **å…³é”®æ ¼å¼**ï¼šæ ‡é¢˜çš„äº•å·ä¸æ–‡å­—ä¹‹é—´**åªèƒ½æœ‰ä¸€ä¸ªç©ºæ ¼**ï¼ˆä¾‹å¦‚ `### æ ‡é¢˜`ï¼‰ï¼Œä¸¥ç¦å‡ºç°ä¸¤ä¸ªç©ºæ ¼æˆ–å…¨è§’ç©ºæ ¼ã€‚
   - è¯·åŠ¡å¿…ä½¿ç”¨ Markdown åŠ ç²—è¯­æ³•ï¼ˆå¦‚ **å…³é”®ç‰¹è´¨**ï¼‰é«˜äº®æ–‡ä¸­é‚£äº›ç›´å‡»çµé­‚ã€åç›´è§‰æˆ–æœ€å…·å†²å‡»åŠ›çš„çŸ­å¥ï¼Œæ¯æ®µè‡³å°‘åŒ…å« 1-2 å¤„é«˜äº®ã€‚

ã€è¾“å‡ºæ¨¡ç‰ˆã€‘
### ï¸ çµé­‚åº•è‰²
(ç”¨ä¸€ä¸ªå¸¦æœ‰ç°åº¦è‰²å½©çš„æ„è±¡ï¼Œå¦‚â€œ**æš´é£é›¨ä¸­çš„ç¯å¡”**â€ï¼Œæè¿°è¯¥äººæ ¼æœ€åº•å±‚çš„æ ¸å¿ƒé©±åŠ¨åŠ›ã€‚çº¦ 100 å­—)

###  é•œåƒä¸é˜´å½±
(æŒ‡å‡ºç”¨æˆ·å¸¸å¸¸æ¬ºéª—è‡ªå·±çš„ä¸€ç‚¹ï¼Œä»¥åŠå¤–ç•Œè¯¯è§£æœ€æ·±çš„ä¸€ç‚¹ã€‚ç”¨â€œä¸–äººçš†ä»¥ä¸º...ï¼Œæ®Šä¸çŸ¥...â€çš„å¥å¼ã€‚çº¦ 150 å­—)

###  ç»™ä¼¤å£çš„è¯—
(é’ˆå¯¹è¯¥äººæ ¼æœ€å®¹æ˜“å—æŒ«çš„è½¯è‚‹ï¼Œå†™ä¸€æ®µæ²»æ„ˆä¸”å……æ»¡åŠ›é‡çš„çŸ­å¥ã€‚çº¦ 80 å­—)
""".strip()

            user_prompt = f"æˆ‘çš„ MBTI ç±»å‹æ˜¯ï¼š{type_code}ã€‚è¯·å¼€å§‹ä½ çš„æ·±åº¦è§£è¯»ã€‚"

            stream = await client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                stream=True,
                timeout=60.0,
            )

            yield "data: [é˜¶æ®µ3] AI å·²æ¥é€šï¼Œå¼€å§‹è¾“å‡º...\n\n"

            async for chunk in stream:
                try:
                    choices = getattr(chunk, "choices", None)
                    if not choices:
                        continue
                    delta = getattr(choices[0], "delta", None)
                    if not delta:
                        continue
                    content = getattr(delta, "content", None)
                    if not content:
                        continue
                    safe_payload = json.dumps(str(content))
                    yield f"data: {safe_payload}\n\n"
                except Exception as loop_err:
                    # å¿½ç•¥å•ä¸ª token çš„å¼‚å¸¸ï¼Œé¿å…æµæ•´ä½“ä¸­æ–­
                    print(f"AI stream chunk error: {loop_err}")
                    continue

        except Exception as e:
            err_msg = str(e)
            print(f"AI Stream Error: {traceback.format_exc()}")
            yield f"data: {json.dumps('âŒ åˆ†æä¸­æ–­: ' + err_msg)}\n\n"
        finally:
            if client:
                try:
                    await client.close()
                except Exception:
                    pass

    headers = {"Cache-Control": "no-cache", "Connection": "keep-alive", "X-Accel-Buffering": "no"}
    return StreamingResponse(event_generator(), media_type="text/event-stream", headers=headers)
